<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="description" content="Controlling diverse robots by inferring Jacobian fields with deep networks" />
  <meta property="og:image" content="./static/images/teaser.png" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>
    Controlling diverse robots by inferring Jacobian fields with deep networks
  </title>

  <!--TWITTER TODO-->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Controlling diverse robots by inferring Jacobian fields with deep networks" />
  <meta name="twitter:image" content="./static/images/teaser.png" />

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

  <link rel="stylesheet" href="./static/css/bulma.min.css" />
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./static/css/index.css" />
  <link rel="icon" href="./static/images/favicon.svg" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    .alert {
      padding: 15px;
      border-radius: 5px;
      margin-bottom: 15px;
      font-family: Arial, sans-serif;
    }

    .alert-primary {
      background-color: #cce5ff;
      color: #004085;
      border: 1px solid #b8daff;
    }

    .tldr {
      font-weight: bold;
    }

    .mb-4 {
      margin-bottom: 1.5rem;
    }
  </style>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              Controlling diverse robots by inferring Jacobian fields with deep networks

            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sizhe-li.github.io/">Sizhe Lester Li</a>,</span>
              <span class="author-block">
                <a href="https://www.annanzhang.com/">Annan Zhang</a>,</span>
              <span class="author-block">
                <a href="https://boyuan.space">Boyuan Chen</a>,</span>
              <span class="author-block">
                <a href="https://dblp.org/pid/345/2163.html"> Hanna Matusik</a>,</span>
              <span class="author-block"><a href="https://chaoliu.tech/">Chao Liu</a>,
              </span>
              <span class="author-block">
                <a href="https://danielarus.csail.mit.edu/">Daniela Rus</a>,
              </span>
              <span class="author-block">
                <a href="https://www.vincentsitzmann.com/">Vincent Sitzmann</a>
              </span>
            </div>

            <br />

            <div class="is-size-5 publication-authors">
              <ul class="affiliation-list">
                <li class="affiliation">
                  <img src="./static/images/mit_logo_std_rgb_black.png" alt="MIT Logo" class="logo" />
                  <img src="./static/images/csail_logo.png" alt="MIT Logo" class="logo" />
                  <img src="./static/images/scene_rep_logo.png" alt="MIT Logo" class="logo" />
                </li>
              </ul>
            </div>
            <br />
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://www.nature.com/articles/s41586-025-09170-0"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=dFZ1RvJMN7A"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/sizhe-li/neural-jacobian-field"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-code"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://sizhe-li.github.io/blog/2025/jacobian-fields-tutorial/"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-code"></i>
                    </span>
                    <span>Tutorial</span>
                  </a>
                </span>
              </div>
            </div>
            <!-- <div class="is-size-5 mt-3">
              <span class="has-text-weight-bold">TL;DR:</span> We introduce
              Neural Jacobian Fields for closed-loop robot control from
              vision. We learn both the robotâ€™s 3D morphology and how its 3D
              points move under any command by observing the robot execute
              random actions from multi-view video. We show control of both
              bio-inspired soft/multi-material and conventional piecewise
              rigid robots using just a single video camera.
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="alert alert-primary tldr mb-4">
          [TL;DR] Neural Jacobian Fields are a representation of robot dynamics learned from perception.
          They can learn to control any robot from a single camera, without any other sensors.
        </div>
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
      </div>
    </div>

  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Technical Summary Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/dFZ1RvJMN7A?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
      <!-- <div class="columns is-centered has-text-centered"> -->
      <!-- <div>
        <div class="is-size-5 mt-3">
          <span class="has-text-weight-bold">(TL;DR)</span>
          Neural Jacobian Fields are
          kinematic representation of robots learned from vision.
        </div>
      </div> -->

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Mirroring the complex structures and diverse functions of natural
            organisms is a long-standing challenge in robotics. Modern
            fabrication techniques have dramatically expanded feasible
            hardware, yet deploying these systems requires control software to
            translate desired motions into actuator commands. While
            conventional robots can easily be modeled as rigid links connected
            via joints, it remains an open challenge to model and control
            bio-inspired robots that are often multi-material or soft, lack
            sensing capabilities, and may change their material properties
            with use. Here, we introduce Neural Jacobian Fields, an
            architecture that autonomously learns to model and control robots
            from vision alone. Our approach makes no assumptions about the
            robot's materials, actuation, or sensing, requires only a single
            camera for control, and learns to control the robot without expert
            intervention by observing the execution of random commands. We
            demonstrate our method on a diverse set of robot manipulators,
            varying in actuation, materials, fabrication, and cost. Our
            approach achieves accurate closed-loop control and recovers the
            causal dynamic structure of each robot. By enabling robot control
            with a generic camera as the only sensor, we anticipate our work
            will dramatically broaden the design space of robotic systems and
            serve as a starting point for lowering the barrier to robotic
            automation.
            <!--/ Abstract. -->
          </div>
        </div>
      </div>

      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Supplmentary Result</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/VC6U0aAwC54?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!-- <div class="content has-text-centered">
        <h2 class="title is-3">Technical Summary Video</h2>
        <video id="replay-video" controls muted preload playsinline width="75%">
          <source src="./static/videos/.mp4" type="video/mp4">
        </video>
      </div> -->

    </div>
  </section>

  <div class="hr"></div>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width has-text-justified">
          <h2 class="title is-3 has-text-centered">
            Controlling robots from vision alone
          </h2>
          <div class="content has-text-justified">
            <p>
              Our model requires only multi-view video of the robot performing random actions to learn
              both its 3D morphology and control through the Neural Jacobian Field.
              The learned model can then be used to plan control commands for desired motions.
            </p>
          </div>
          <br />
          <div class="content has-text-centered">
            <img src="./static/images/data.png" class="inline-figure-six" alt="Neural Jacobian Field Data." />
          </div>
          <div class="content has-text-justified">
            <p>
              First, we sample random control commands to be executed on the robot. Using a setup of 12 RGB-D cameras,
              we record multi-view captures both before each command is executed and after each command has settled into
              a steady state, forming our dataset.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/training.png" class="inline-figure-six" alt="Neural Jacobian Field Training." />
          </div>
          <div class="content has-text-justified">
            <p>
              Using the above dataset, our method learns a mapping from a single RGB image to a neural scene
              representation. This scene representation combines a Radiance Field, which contains visual and geometric
              information, with a Jacobian Field, which contains the kinematics information of the scene. We refer to
              this combined representation as the Neural Jacobian Field.
            </p>
          </div>
          <br />
          <div class="content has-text-centered">
            <img src="./static/images/teaser.png" class="inline-figure-six" alt="Neural Jacobian Field." />
          </div>
          <br />
          <div class="content has-text-justified">
            <p>
              The Neural Jacobian Field can be used to query the kinematics Jacobian at every coordinate in the 3D scene
              with respect to the robot's control commands. This capability allows us to visually identify the
              kinematics chain and plan a sequence of control commands for a desired motion using gradient-based
              optimization.
            </p>
          </div>
          <br />
        </div>
      </div>
    </div>
  </section>

  <div class="hr"></div>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width has-text-justified">
          <h2 class="title is-3 has-text-centered">Results</h2>
          <div class="content has-text-justified">
            <p>
              With the Neural Jacobian Field, we can visualize the robot's geometry and kinematics inferred from a
              single image. The figure below shows the predicted depth and colorized kinematics chain as derived from
              the Neural
              Jacobian Field. <b> The colorization is completely learned and not labeled by a human. </b>
            </p>
          </div>

          <div class="content has-text-centered">
            <img src="./static/images/kinematics.jpg" class="inline-figure-six" height="auto" width="100%" />

            <hr />
          </div>

          <div class="content has-text-justified">
            <p>
              Our method can perform closed-loop control of diverse
              robots from vision, including soft robots that are traditionally
              hard to model, and a $220 3D-printed janky robot arm.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/control.png" class="inline-figure-six" height="auto" width="100%" />
          </div>

          <div class="content has-text-justified">
            <p>
              Quantitatively, our controller can effectively reduce the distance-to-goal for specified motion in the
              form of point movement, providing a viable method to control robots that are traditionally impossible to
              control, due to challenges in estimating their kinematic structures.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/quantitative.png" class="inline-figure-six" height="auto" width="100%" />
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title has-text-centered">BibTeX</h2>
      <pre><code>
        @Article{Li2025,
        author={Li, Sizhe Lester
        and Zhang, Annan
        and Chen, Boyuan
        and Matusik, Hanna
        and Liu, Chao
        and Rus, Daniela
        and Sitzmann, Vincent},
        title={Controlling diverse robots by inferring Jacobian fields with deep networks},
        journal={Nature},
        year={2025},
        month={Jun},
        day={25},
        issn={1476-4687},
        doi={10.1038/s41586-025-09170-0},
        url={https://doi.org/10.1038/s41586-025-09170-0}  
        }
        </code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://www.nature.com/articles/s41586-025-09170-0">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="todo" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Website template is modified from
              <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>